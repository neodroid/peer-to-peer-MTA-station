import {
  pushable
} from "./chunk-E4JTUZPO.js";
import {
  raceSignal
} from "./chunk-3W5ODUXV.js";
import {
  peerIdFromString
} from "./chunk-MUJBFYE2.js";
import {
  pDefer
} from "./chunk-GYD5GS2D.js";
import {
  AbortError,
  CodeError,
  TypedEventEmitter,
  setMaxListeners
} from "./chunk-Q7O7U65G.js";
import {
  __commonJS,
  __toESM
} from "./chunk-NNBXUUFX.js";

// node_modules/murmurhash3js-revisited/lib/murmurHash3js.js
var require_murmurHash3js = __commonJS({
  "node_modules/murmurhash3js-revisited/lib/murmurHash3js.js"(exports, module) {
    (function(root, undefined2) {
      "use strict";
      var library = {
        "version": "3.0.0",
        "x86": {},
        "x64": {},
        "inputValidation": true
      };
      function _validBytes(bytes) {
        if (!Array.isArray(bytes) && !ArrayBuffer.isView(bytes)) {
          return false;
        }
        for (var i = 0; i < bytes.length; i++) {
          if (!Number.isInteger(bytes[i]) || bytes[i] < 0 || bytes[i] > 255) {
            return false;
          }
        }
        return true;
      }
      function _x86Multiply(m, n) {
        return (m & 65535) * n + (((m >>> 16) * n & 65535) << 16);
      }
      function _x86Rotl(m, n) {
        return m << n | m >>> 32 - n;
      }
      function _x86Fmix(h) {
        h ^= h >>> 16;
        h = _x86Multiply(h, 2246822507);
        h ^= h >>> 13;
        h = _x86Multiply(h, 3266489909);
        h ^= h >>> 16;
        return h;
      }
      function _x64Add(m, n) {
        m = [m[0] >>> 16, m[0] & 65535, m[1] >>> 16, m[1] & 65535];
        n = [n[0] >>> 16, n[0] & 65535, n[1] >>> 16, n[1] & 65535];
        var o = [0, 0, 0, 0];
        o[3] += m[3] + n[3];
        o[2] += o[3] >>> 16;
        o[3] &= 65535;
        o[2] += m[2] + n[2];
        o[1] += o[2] >>> 16;
        o[2] &= 65535;
        o[1] += m[1] + n[1];
        o[0] += o[1] >>> 16;
        o[1] &= 65535;
        o[0] += m[0] + n[0];
        o[0] &= 65535;
        return [o[0] << 16 | o[1], o[2] << 16 | o[3]];
      }
      function _x64Multiply(m, n) {
        m = [m[0] >>> 16, m[0] & 65535, m[1] >>> 16, m[1] & 65535];
        n = [n[0] >>> 16, n[0] & 65535, n[1] >>> 16, n[1] & 65535];
        var o = [0, 0, 0, 0];
        o[3] += m[3] * n[3];
        o[2] += o[3] >>> 16;
        o[3] &= 65535;
        o[2] += m[2] * n[3];
        o[1] += o[2] >>> 16;
        o[2] &= 65535;
        o[2] += m[3] * n[2];
        o[1] += o[2] >>> 16;
        o[2] &= 65535;
        o[1] += m[1] * n[3];
        o[0] += o[1] >>> 16;
        o[1] &= 65535;
        o[1] += m[2] * n[2];
        o[0] += o[1] >>> 16;
        o[1] &= 65535;
        o[1] += m[3] * n[1];
        o[0] += o[1] >>> 16;
        o[1] &= 65535;
        o[0] += m[0] * n[3] + m[1] * n[2] + m[2] * n[1] + m[3] * n[0];
        o[0] &= 65535;
        return [o[0] << 16 | o[1], o[2] << 16 | o[3]];
      }
      function _x64Rotl(m, n) {
        n %= 64;
        if (n === 32) {
          return [m[1], m[0]];
        } else if (n < 32) {
          return [m[0] << n | m[1] >>> 32 - n, m[1] << n | m[0] >>> 32 - n];
        } else {
          n -= 32;
          return [m[1] << n | m[0] >>> 32 - n, m[0] << n | m[1] >>> 32 - n];
        }
      }
      function _x64LeftShift(m, n) {
        n %= 64;
        if (n === 0) {
          return m;
        } else if (n < 32) {
          return [m[0] << n | m[1] >>> 32 - n, m[1] << n];
        } else {
          return [m[1] << n - 32, 0];
        }
      }
      function _x64Xor(m, n) {
        return [m[0] ^ n[0], m[1] ^ n[1]];
      }
      function _x64Fmix(h) {
        h = _x64Xor(h, [0, h[0] >>> 1]);
        h = _x64Multiply(h, [4283543511, 3981806797]);
        h = _x64Xor(h, [0, h[0] >>> 1]);
        h = _x64Multiply(h, [3301882366, 444984403]);
        h = _x64Xor(h, [0, h[0] >>> 1]);
        return h;
      }
      library.x86.hash32 = function(bytes, seed) {
        if (library.inputValidation && !_validBytes(bytes)) {
          return undefined2;
        }
        seed = seed || 0;
        var remainder = bytes.length % 4;
        var blocks = bytes.length - remainder;
        var h1 = seed;
        var k1 = 0;
        var c1 = 3432918353;
        var c2 = 461845907;
        for (var i = 0; i < blocks; i = i + 4) {
          k1 = bytes[i] | bytes[i + 1] << 8 | bytes[i + 2] << 16 | bytes[i + 3] << 24;
          k1 = _x86Multiply(k1, c1);
          k1 = _x86Rotl(k1, 15);
          k1 = _x86Multiply(k1, c2);
          h1 ^= k1;
          h1 = _x86Rotl(h1, 13);
          h1 = _x86Multiply(h1, 5) + 3864292196;
        }
        k1 = 0;
        switch (remainder) {
          case 3:
            k1 ^= bytes[i + 2] << 16;
          case 2:
            k1 ^= bytes[i + 1] << 8;
          case 1:
            k1 ^= bytes[i];
            k1 = _x86Multiply(k1, c1);
            k1 = _x86Rotl(k1, 15);
            k1 = _x86Multiply(k1, c2);
            h1 ^= k1;
        }
        h1 ^= bytes.length;
        h1 = _x86Fmix(h1);
        return h1 >>> 0;
      };
      library.x86.hash128 = function(bytes, seed) {
        if (library.inputValidation && !_validBytes(bytes)) {
          return undefined2;
        }
        seed = seed || 0;
        var remainder = bytes.length % 16;
        var blocks = bytes.length - remainder;
        var h1 = seed;
        var h2 = seed;
        var h3 = seed;
        var h4 = seed;
        var k1 = 0;
        var k2 = 0;
        var k3 = 0;
        var k4 = 0;
        var c1 = 597399067;
        var c2 = 2869860233;
        var c3 = 951274213;
        var c4 = 2716044179;
        for (var i = 0; i < blocks; i = i + 16) {
          k1 = bytes[i] | bytes[i + 1] << 8 | bytes[i + 2] << 16 | bytes[i + 3] << 24;
          k2 = bytes[i + 4] | bytes[i + 5] << 8 | bytes[i + 6] << 16 | bytes[i + 7] << 24;
          k3 = bytes[i + 8] | bytes[i + 9] << 8 | bytes[i + 10] << 16 | bytes[i + 11] << 24;
          k4 = bytes[i + 12] | bytes[i + 13] << 8 | bytes[i + 14] << 16 | bytes[i + 15] << 24;
          k1 = _x86Multiply(k1, c1);
          k1 = _x86Rotl(k1, 15);
          k1 = _x86Multiply(k1, c2);
          h1 ^= k1;
          h1 = _x86Rotl(h1, 19);
          h1 += h2;
          h1 = _x86Multiply(h1, 5) + 1444728091;
          k2 = _x86Multiply(k2, c2);
          k2 = _x86Rotl(k2, 16);
          k2 = _x86Multiply(k2, c3);
          h2 ^= k2;
          h2 = _x86Rotl(h2, 17);
          h2 += h3;
          h2 = _x86Multiply(h2, 5) + 197830471;
          k3 = _x86Multiply(k3, c3);
          k3 = _x86Rotl(k3, 17);
          k3 = _x86Multiply(k3, c4);
          h3 ^= k3;
          h3 = _x86Rotl(h3, 15);
          h3 += h4;
          h3 = _x86Multiply(h3, 5) + 2530024501;
          k4 = _x86Multiply(k4, c4);
          k4 = _x86Rotl(k4, 18);
          k4 = _x86Multiply(k4, c1);
          h4 ^= k4;
          h4 = _x86Rotl(h4, 13);
          h4 += h1;
          h4 = _x86Multiply(h4, 5) + 850148119;
        }
        k1 = 0;
        k2 = 0;
        k3 = 0;
        k4 = 0;
        switch (remainder) {
          case 15:
            k4 ^= bytes[i + 14] << 16;
          case 14:
            k4 ^= bytes[i + 13] << 8;
          case 13:
            k4 ^= bytes[i + 12];
            k4 = _x86Multiply(k4, c4);
            k4 = _x86Rotl(k4, 18);
            k4 = _x86Multiply(k4, c1);
            h4 ^= k4;
          case 12:
            k3 ^= bytes[i + 11] << 24;
          case 11:
            k3 ^= bytes[i + 10] << 16;
          case 10:
            k3 ^= bytes[i + 9] << 8;
          case 9:
            k3 ^= bytes[i + 8];
            k3 = _x86Multiply(k3, c3);
            k3 = _x86Rotl(k3, 17);
            k3 = _x86Multiply(k3, c4);
            h3 ^= k3;
          case 8:
            k2 ^= bytes[i + 7] << 24;
          case 7:
            k2 ^= bytes[i + 6] << 16;
          case 6:
            k2 ^= bytes[i + 5] << 8;
          case 5:
            k2 ^= bytes[i + 4];
            k2 = _x86Multiply(k2, c2);
            k2 = _x86Rotl(k2, 16);
            k2 = _x86Multiply(k2, c3);
            h2 ^= k2;
          case 4:
            k1 ^= bytes[i + 3] << 24;
          case 3:
            k1 ^= bytes[i + 2] << 16;
          case 2:
            k1 ^= bytes[i + 1] << 8;
          case 1:
            k1 ^= bytes[i];
            k1 = _x86Multiply(k1, c1);
            k1 = _x86Rotl(k1, 15);
            k1 = _x86Multiply(k1, c2);
            h1 ^= k1;
        }
        h1 ^= bytes.length;
        h2 ^= bytes.length;
        h3 ^= bytes.length;
        h4 ^= bytes.length;
        h1 += h2;
        h1 += h3;
        h1 += h4;
        h2 += h1;
        h3 += h1;
        h4 += h1;
        h1 = _x86Fmix(h1);
        h2 = _x86Fmix(h2);
        h3 = _x86Fmix(h3);
        h4 = _x86Fmix(h4);
        h1 += h2;
        h1 += h3;
        h1 += h4;
        h2 += h1;
        h3 += h1;
        h4 += h1;
        return ("00000000" + (h1 >>> 0).toString(16)).slice(-8) + ("00000000" + (h2 >>> 0).toString(16)).slice(-8) + ("00000000" + (h3 >>> 0).toString(16)).slice(-8) + ("00000000" + (h4 >>> 0).toString(16)).slice(-8);
      };
      library.x64.hash128 = function(bytes, seed) {
        if (library.inputValidation && !_validBytes(bytes)) {
          return undefined2;
        }
        seed = seed || 0;
        var remainder = bytes.length % 16;
        var blocks = bytes.length - remainder;
        var h1 = [0, seed];
        var h2 = [0, seed];
        var k1 = [0, 0];
        var k2 = [0, 0];
        var c1 = [2277735313, 289559509];
        var c2 = [1291169091, 658871167];
        for (var i = 0; i < blocks; i = i + 16) {
          k1 = [bytes[i + 4] | bytes[i + 5] << 8 | bytes[i + 6] << 16 | bytes[i + 7] << 24, bytes[i] | bytes[i + 1] << 8 | bytes[i + 2] << 16 | bytes[i + 3] << 24];
          k2 = [bytes[i + 12] | bytes[i + 13] << 8 | bytes[i + 14] << 16 | bytes[i + 15] << 24, bytes[i + 8] | bytes[i + 9] << 8 | bytes[i + 10] << 16 | bytes[i + 11] << 24];
          k1 = _x64Multiply(k1, c1);
          k1 = _x64Rotl(k1, 31);
          k1 = _x64Multiply(k1, c2);
          h1 = _x64Xor(h1, k1);
          h1 = _x64Rotl(h1, 27);
          h1 = _x64Add(h1, h2);
          h1 = _x64Add(_x64Multiply(h1, [0, 5]), [0, 1390208809]);
          k2 = _x64Multiply(k2, c2);
          k2 = _x64Rotl(k2, 33);
          k2 = _x64Multiply(k2, c1);
          h2 = _x64Xor(h2, k2);
          h2 = _x64Rotl(h2, 31);
          h2 = _x64Add(h2, h1);
          h2 = _x64Add(_x64Multiply(h2, [0, 5]), [0, 944331445]);
        }
        k1 = [0, 0];
        k2 = [0, 0];
        switch (remainder) {
          case 15:
            k2 = _x64Xor(k2, _x64LeftShift([0, bytes[i + 14]], 48));
          case 14:
            k2 = _x64Xor(k2, _x64LeftShift([0, bytes[i + 13]], 40));
          case 13:
            k2 = _x64Xor(k2, _x64LeftShift([0, bytes[i + 12]], 32));
          case 12:
            k2 = _x64Xor(k2, _x64LeftShift([0, bytes[i + 11]], 24));
          case 11:
            k2 = _x64Xor(k2, _x64LeftShift([0, bytes[i + 10]], 16));
          case 10:
            k2 = _x64Xor(k2, _x64LeftShift([0, bytes[i + 9]], 8));
          case 9:
            k2 = _x64Xor(k2, [0, bytes[i + 8]]);
            k2 = _x64Multiply(k2, c2);
            k2 = _x64Rotl(k2, 33);
            k2 = _x64Multiply(k2, c1);
            h2 = _x64Xor(h2, k2);
          case 8:
            k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 7]], 56));
          case 7:
            k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 6]], 48));
          case 6:
            k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 5]], 40));
          case 5:
            k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 4]], 32));
          case 4:
            k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 3]], 24));
          case 3:
            k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 2]], 16));
          case 2:
            k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 1]], 8));
          case 1:
            k1 = _x64Xor(k1, [0, bytes[i]]);
            k1 = _x64Multiply(k1, c1);
            k1 = _x64Rotl(k1, 31);
            k1 = _x64Multiply(k1, c2);
            h1 = _x64Xor(h1, k1);
        }
        h1 = _x64Xor(h1, [0, bytes.length]);
        h2 = _x64Xor(h2, [0, bytes.length]);
        h1 = _x64Add(h1, h2);
        h2 = _x64Add(h2, h1);
        h1 = _x64Fmix(h1);
        h2 = _x64Fmix(h2);
        h1 = _x64Add(h1, h2);
        h2 = _x64Add(h2, h1);
        return ("00000000" + (h1[0] >>> 0).toString(16)).slice(-8) + ("00000000" + (h1[1] >>> 0).toString(16)).slice(-8) + ("00000000" + (h2[0] >>> 0).toString(16)).slice(-8) + ("00000000" + (h2[1] >>> 0).toString(16)).slice(-8);
      };
      if (typeof exports !== "undefined") {
        if (typeof module !== "undefined" && module.exports) {
          exports = module.exports = library;
        }
        exports.murmurHash3 = library;
      } else if (typeof define === "function" && define.amd) {
        define([], function() {
          return library;
        });
      } else {
        library._murmurHash3 = root.murmurHash3;
        library.noConflict = function() {
          root.murmurHash3 = library._murmurHash3;
          library._murmurHash3 = undefined2;
          library.noConflict = undefined2;
          return library;
        };
        root.murmurHash3 = library;
      }
    })(exports);
  }
});

// node_modules/murmurhash3js-revisited/index.js
var require_murmurhash3js_revisited = __commonJS({
  "node_modules/murmurhash3js-revisited/index.js"(exports, module) {
    module.exports = require_murmurHash3js();
  }
});

// node_modules/@libp2p/peer-collections/dist/src/util.js
function mapIterable(iter, map) {
  const iterator = {
    [Symbol.iterator]: () => {
      return iterator;
    },
    next: () => {
      const next = iter.next();
      const val = next.value;
      if (next.done === true || val == null) {
        const result = {
          done: true,
          value: void 0
        };
        return result;
      }
      return {
        done: false,
        value: map(val)
      };
    }
  };
  return iterator;
}

// node_modules/@libp2p/peer-collections/dist/src/set.js
var PeerSet = class _PeerSet {
  set;
  constructor(set) {
    this.set = /* @__PURE__ */ new Set();
    if (set != null) {
      for (const key of set) {
        this.set.add(key.toString());
      }
    }
  }
  get size() {
    return this.set.size;
  }
  [Symbol.iterator]() {
    return this.values();
  }
  add(peer) {
    this.set.add(peer.toString());
  }
  clear() {
    this.set.clear();
  }
  delete(peer) {
    this.set.delete(peer.toString());
  }
  entries() {
    return mapIterable(this.set.entries(), (val) => {
      const peerId = peerIdFromString(val[0]);
      return [peerId, peerId];
    });
  }
  forEach(predicate) {
    this.set.forEach((str) => {
      const id = peerIdFromString(str);
      predicate(id, id, this);
    });
  }
  has(peer) {
    return this.set.has(peer.toString());
  }
  values() {
    return mapIterable(this.set.values(), (val) => {
      return peerIdFromString(val);
    });
  }
  intersection(other) {
    const output = new _PeerSet();
    for (const peerId of other) {
      if (this.has(peerId)) {
        output.add(peerId);
      }
    }
    return output;
  }
  difference(other) {
    const output = new _PeerSet();
    for (const peerId of this) {
      if (!other.has(peerId)) {
        output.add(peerId);
      }
    }
    return output;
  }
  union(other) {
    const output = new _PeerSet();
    for (const peerId of other) {
      output.add(peerId);
    }
    for (const peerId of this) {
      output.add(peerId);
    }
    return output;
  }
};

// node_modules/@libp2p/peer-collections/dist/src/map.js
var PeerMap = class {
  map;
  constructor(map) {
    this.map = /* @__PURE__ */ new Map();
    if (map != null) {
      for (const [key, value] of map.entries()) {
        this.map.set(key.toString(), value);
      }
    }
  }
  [Symbol.iterator]() {
    return this.entries();
  }
  clear() {
    this.map.clear();
  }
  delete(peer) {
    return this.map.delete(peer.toString());
  }
  entries() {
    return mapIterable(this.map.entries(), (val) => {
      return [peerIdFromString(val[0]), val[1]];
    });
  }
  forEach(fn) {
    this.map.forEach((value, key) => {
      fn(value, peerIdFromString(key), this);
    });
  }
  get(peer) {
    return this.map.get(peer.toString());
  }
  has(peer) {
    return this.map.has(peer.toString());
  }
  set(peer, value) {
    this.map.set(peer.toString(), value);
  }
  keys() {
    return mapIterable(this.map.keys(), (val) => {
      return peerIdFromString(val);
    });
  }
  values() {
    return this.map.values();
  }
  get size() {
    return this.map.size;
  }
};

// node_modules/@libp2p/utils/dist/src/filters/bloom-filter.js
var import_murmurhash3js_revisited = __toESM(require_murmurhash3js_revisited(), 1);
var LN2_SQUARED = Math.LN2 * Math.LN2;

// node_modules/@sindresorhus/fnv1a/index.js
var cachedEncoder = new globalThis.TextEncoder();

// node_modules/@libp2p/utils/dist/src/filters/hashes.js
var import_murmurhash3js_revisited2 = __toESM(require_murmurhash3js_revisited(), 1);

// node_modules/any-signal/dist/src/index.js
function anySignal(signals) {
  const controller = new globalThis.AbortController();
  function onAbort() {
    controller.abort();
    for (const signal2 of signals) {
      if (signal2?.removeEventListener != null) {
        signal2.removeEventListener("abort", onAbort);
      }
    }
  }
  for (const signal2 of signals) {
    if (signal2?.aborted === true) {
      onAbort();
      break;
    }
    if (signal2?.addEventListener != null) {
      signal2.addEventListener("abort", onAbort);
    }
  }
  function clear() {
    for (const signal2 of signals) {
      if (signal2?.removeEventListener != null) {
        signal2.removeEventListener("abort", onAbort);
      }
    }
  }
  const signal = controller.signal;
  signal.clear = clear;
  return signal;
}

// node_modules/race-event/dist/src/index.js
var AbortError2 = class extends Error {
  type;
  code;
  constructor(message, code) {
    super(message ?? "The operation was aborted");
    this.type = "aborted";
    this.name = "AbortError";
    this.code = code ?? "ABORT_ERR";
  }
};
async function raceEvent(emitter, eventName, signal, opts) {
  const error = new AbortError2(opts?.errorMessage, opts?.errorCode);
  if (signal?.aborted === true) {
    return Promise.reject(error);
  }
  return new Promise((resolve, reject) => {
    function removeListeners() {
      signal?.removeEventListener("abort", abortListener);
      emitter.removeEventListener(eventName, eventListener);
      if (opts?.errorEvent != null) {
        emitter.removeEventListener(opts.errorEvent, errorEventListener);
      }
    }
    const eventListener = (evt) => {
      try {
        if (opts?.filter?.(evt) === false) {
          return;
        }
      } catch (err) {
        removeListeners();
        reject(err);
        return;
      }
      removeListeners();
      resolve(evt);
    };
    const errorEventListener = (evt) => {
      removeListeners();
      reject(evt.detail);
    };
    const abortListener = () => {
      removeListeners();
      reject(error);
    };
    signal?.addEventListener("abort", abortListener);
    emitter.addEventListener(eventName, eventListener);
    if (opts?.errorEvent != null) {
      emitter.addEventListener(opts.errorEvent, errorEventListener);
    }
  });
}

// node_modules/@libp2p/utils/dist/src/queue/recipient.js
var JobRecipient = class {
  deferred;
  signal;
  where;
  constructor(where, signal) {
    this.signal = signal;
    this.deferred = pDefer();
    this.where = where;
    this.onAbort = this.onAbort.bind(this);
    this.signal?.addEventListener("abort", this.onAbort);
  }
  onAbort() {
    this.deferred.reject(this.signal?.reason ?? new AbortError());
  }
  cleanup() {
    this.signal?.removeEventListener("abort", this.onAbort);
  }
};

// node_modules/@libp2p/utils/dist/src/queue/job.js
function randomId() {
  return `${parseInt(String(Math.random() * 1e9), 10).toString()}${Date.now()}`;
}
var Job = class {
  id;
  fn;
  options;
  priority;
  recipients;
  status;
  timeline;
  controller;
  constructor(fn, options, priority = 0) {
    this.id = randomId();
    this.status = "queued";
    this.fn = fn;
    this.priority = priority;
    this.options = options;
    this.recipients = [];
    this.timeline = {
      created: Date.now()
    };
    this.controller = new AbortController();
    setMaxListeners(Infinity, this.controller.signal);
    this.onAbort = this.onAbort.bind(this);
  }
  abort(err) {
    this.controller.abort(err);
  }
  onAbort() {
    const allAborted = this.recipients.reduce((acc, curr) => {
      return acc && curr.signal?.aborted === true;
    }, true);
    if (allAborted) {
      this.controller.abort(new AbortError());
      this.cleanup();
    }
  }
  async join(options = {}) {
    const recipient = new JobRecipient(new Error("where").stack, options.signal);
    this.recipients.push(recipient);
    options.signal?.addEventListener("abort", this.onAbort);
    return recipient.deferred.promise;
  }
  async run() {
    this.status = "running";
    this.timeline.started = Date.now();
    try {
      this.controller.signal.throwIfAborted();
      const result = await raceSignal(this.fn({
        ...this.options ?? {},
        signal: this.controller.signal
      }), this.controller.signal);
      this.recipients.forEach((recipient) => {
        recipient.deferred.resolve(result);
      });
      this.status = "complete";
    } catch (err) {
      this.recipients.forEach((recipient) => {
        recipient.deferred.reject(err);
      });
      this.status = "errored";
    } finally {
      this.timeline.finished = Date.now();
      this.cleanup();
    }
  }
  cleanup() {
    this.recipients.forEach((recipient) => {
      recipient.cleanup();
      recipient.signal?.removeEventListener("abort", this.onAbort);
    });
  }
};

// node_modules/@libp2p/utils/dist/src/queue/index.js
function lowerBound(array, value, comparator) {
  let first = 0;
  let count = array.length;
  while (count > 0) {
    const step = Math.trunc(count / 2);
    let it = first + step;
    if (comparator(array[it], value) <= 0) {
      first = ++it;
      count -= step + 1;
    } else {
      count = step;
    }
  }
  return first;
}
var Queue = class extends TypedEventEmitter {
  concurrency;
  queue;
  pending;
  constructor(init = {}) {
    super();
    this.concurrency = init.concurrency ?? Number.POSITIVE_INFINITY;
    this.pending = 0;
    if (init.metricName != null) {
      init.metrics?.registerMetricGroup(init.metricName, {
        calculate: () => {
          return {
            size: this.queue.length,
            running: this.pending,
            queued: this.queue.length - this.pending
          };
        }
      });
    }
    this.queue = [];
  }
  tryToStartAnother() {
    if (this.size === 0) {
      queueMicrotask(() => {
        this.safeDispatchEvent("empty");
      });
      if (this.running === 0) {
        queueMicrotask(() => {
          this.safeDispatchEvent("idle");
        });
      }
      return false;
    }
    if (this.pending < this.concurrency) {
      let job;
      for (const j of this.queue) {
        if (j.status === "queued") {
          job = j;
          break;
        }
      }
      if (job == null) {
        return false;
      }
      this.safeDispatchEvent("active");
      this.pending++;
      job.run().finally(() => {
        for (let i = 0; i < this.queue.length; i++) {
          if (this.queue[i] === job) {
            this.queue.splice(i, 1);
            break;
          }
        }
        this.pending--;
        this.tryToStartAnother();
        this.safeDispatchEvent("next");
      });
      return true;
    }
    return false;
  }
  enqueue(job) {
    if (this.queue[this.size - 1]?.priority >= job.priority) {
      this.queue.push(job);
      return;
    }
    const index = lowerBound(this.queue, job, (a, b) => b.priority - a.priority);
    this.queue.splice(index, 0, job);
  }
  /**
   * Adds a sync or async task to the queue. Always returns a promise.
   */
  async add(fn, options) {
    options?.signal?.throwIfAborted();
    const job = new Job(fn, options, options?.priority);
    const p = job.join(options).then((result) => {
      this.safeDispatchEvent("completed", { detail: result });
      this.safeDispatchEvent("success", { detail: { job, result } });
      return result;
    }).catch((err) => {
      if (job.status === "queued") {
        for (let i = 0; i < this.queue.length; i++) {
          if (this.queue[i] === job) {
            this.queue.splice(i, 1);
            break;
          }
        }
      }
      this.safeDispatchEvent("error", { detail: err });
      this.safeDispatchEvent("failure", { detail: { job, error: err } });
      throw err;
    });
    this.enqueue(job);
    this.safeDispatchEvent("add");
    this.tryToStartAnother();
    return p;
  }
  /**
   * Clear the queue
   */
  clear() {
    this.queue.splice(0, this.queue.length);
  }
  /**
   * Abort all jobs in the queue and clear it
   */
  abort() {
    this.queue.forEach((job) => {
      job.abort(new AbortError());
    });
    this.clear();
  }
  /**
   * Can be called multiple times. Useful if you for example add additional items at a later time.
   *
   * @returns A promise that settles when the queue becomes empty.
   */
  async onEmpty(options) {
    if (this.size === 0) {
      return;
    }
    await raceEvent(this, "empty", options?.signal);
  }
  /**
   * @returns A promise that settles when the queue size is less than the given
   * limit: `queue.size < limit`.
   *
   * If you want to avoid having the queue grow beyond a certain size you can
   * `await queue.onSizeLessThan()` before adding a new item.
   *
   * Note that this only limits the number of items waiting to start. There
   * could still be up to `concurrency` jobs already running that this call does
   * not include in its calculation.
   */
  async onSizeLessThan(limit, options) {
    if (this.size < limit) {
      return;
    }
    await raceEvent(this, "next", options?.signal, {
      filter: () => this.size < limit
    });
  }
  /**
   * The difference with `.onEmpty` is that `.onIdle` guarantees that all work
   * from the queue has finished. `.onEmpty` merely signals that the queue is
   * empty, but it could mean that some promises haven't completed yet.
   *
   * @returns A promise that settles when the queue becomes empty, and all
   * promises have completed; `queue.size === 0 && queue.pending === 0`.
   */
  async onIdle(options) {
    if (this.pending === 0 && this.size === 0) {
      return;
    }
    await raceEvent(this, "idle", options?.signal);
  }
  /**
   * Size of the queue including running items
   */
  get size() {
    return this.queue.length;
  }
  /**
   * The number of queued items waiting to run.
   */
  get queued() {
    return this.queue.length - this.pending;
  }
  /**
   * The number of items currently running.
   */
  get running() {
    return this.pending;
  }
  /**
   * Returns an async generator that makes it easy to iterate over the results
   * of jobs added to the queue.
   *
   * The generator will end when the queue becomes idle, that is there are no
   * jobs running and no jobs that have yet to run.
   *
   * If you need to keep the queue open indefinitely, consider using it-pushable
   * instead.
   */
  async *toGenerator(options) {
    options?.signal?.throwIfAborted();
    const stream = pushable({
      objectMode: true
    });
    const cleanup = (err) => {
      if (err != null) {
        this.abort();
      } else {
        this.clear();
      }
      stream.end(err);
    };
    const onQueueJobComplete = (evt) => {
      if (evt.detail != null) {
        stream.push(evt.detail);
      }
    };
    const onQueueError = (evt) => {
      cleanup(evt.detail);
    };
    const onQueueIdle = () => {
      cleanup();
    };
    const onSignalAbort = () => {
      cleanup(new CodeError("Queue aborted", "ERR_QUEUE_ABORTED"));
    };
    this.addEventListener("completed", onQueueJobComplete);
    this.addEventListener("error", onQueueError);
    this.addEventListener("idle", onQueueIdle);
    options?.signal?.addEventListener("abort", onSignalAbort);
    try {
      yield* stream;
    } finally {
      this.removeEventListener("completed", onQueueJobComplete);
      this.removeEventListener("error", onQueueError);
      this.removeEventListener("idle", onQueueIdle);
      options?.signal?.removeEventListener("abort", onSignalAbort);
      cleanup();
    }
  }
};

// node_modules/@libp2p/utils/dist/src/peer-queue.js
var PeerQueue = class extends Queue {
  has(peerId) {
    return this.find(peerId) != null;
  }
  find(peerId) {
    return this.queue.find((job) => {
      return peerId.equals(job.options.peerId);
    });
  }
};

export {
  anySignal,
  PeerMap,
  PeerSet,
  raceEvent,
  Queue,
  PeerQueue
};
//# sourceMappingURL=chunk-BIAJMC7X.js.map
